{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommenders 3 -- Sequence Recommenders (45m) \n",
    "\n",
    "## Goals of this practical:\n",
    "\n",
    "- Understand the sequence recommendation framework (~5min)\n",
    "- Load/Format dataset (~5min)\n",
    "- Understand/train the prod2vec model (~10min)\n",
    "- Evaluate (~10min)\n",
    "- Visualize (~10min)\n",
    "- Fiddle (~5min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install gensim --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Recommenders:\n",
    "\n",
    "> What will you click next ?\n",
    "\n",
    "The sequence recommendation setting is a particular case of the implicit collaborative filtering setting. Given a sequence of items $i_0,i_1,...,i_n$ the goal is to predict the $i_{(n+1)},...$ items the user will consume. Playlist continuation is a neat use case of sequence recommenders. You've been listening to those songs, what can you listen to now ?\n",
    "\n",
    "\n",
    "This setting differs from the classical collaborative filtering because the history is the recent trace and not the full saved interactions. Also, it's possible to do sequence recommendation without any specific latent user profile. \n",
    "\n",
    "####Â Here we propose to explore this unpersonalized sequence recommandation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used : [smallest movie-lens dataset](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "Here we'll use the same data as before but instead of seeing $(user,item,rating)$ triplets or a $(user,item)$ interaction , we'll see item sequences: $user: [item, item,...]$\n",
    "\n",
    "## Loading Data (same as before but in chronological order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66719</th>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>429</td>\n",
       "      <td>588</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66717</th>\n",
       "      <td>429</td>\n",
       "      <td>590</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66718</th>\n",
       "      <td>429</td>\n",
       "      <td>592</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66712</th>\n",
       "      <td>429</td>\n",
       "      <td>432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating  timestamp\n",
       "66719     429      595     5.0  828124615\n",
       "66716     429      588     5.0  828124615\n",
       "66717     429      590     5.0  828124615\n",
       "66718     429      592     5.0  828124615\n",
       "66712     429      432     3.0  828124615"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load the ratings\n",
    "ratings = pd.read_csv(\"dataset/ratings.csv\")\n",
    "ratings = ratings.sort_values(\"timestamp\",ascending=True)\n",
    "print(ratings.iloc[0][\"timestamp\"] < ratings.iloc[-1][\"timestamp\"] ) # just checking\n",
    "\n",
    "# Let's check what the ratings look like\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also load titles and create an id2title dictionnary\n",
    "titleCSV = pd.read_csv(\"dataset/movies.csv\")\n",
    "id2title = titleCSV[[\"movieId\",\"title\"]].set_index(\"movieId\").to_dict()[\"title\"]\n",
    "\n",
    "# Let's check wthat the titles look like\n",
    "titleCSV.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Create sequence datasets:\n",
    "For this task, we need sequences of items as data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo): extract all movie sequences (in chronological order) from the dataset:\n",
    "\n",
    "\n",
    "In this dataset, each user has seen at least 20 movies.\n",
    "\n",
    "\n",
    "- We need to extract all movie rating sequences (there is one per user) from the dataset:\n",
    "\n",
    "`sequence_of_movies = [[movieid,...],[movieid,...],...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_of_movies = [list(ratings[ratings[\"userId\"] == id][\"movieId\"].values) for id in ratings[\"userId\"].unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo): Create a train/test dataset\n",
    "\n",
    "Here, we propose as task to predict the last 5 items of each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq,test_seq = [],[]\n",
    "\n",
    "# We take for last 5 for the test sequence and the remaining ones for the train sequence\n",
    "for seq in sequences_of_movies:\n",
    "    train_seq.append(seq[:-5])\n",
    "    test_seq.append(seq[-5:])\n",
    "    \n",
    "last_consumed_item = [seq[-1] for seq in train_seq] # We save the last consumed item for each list\n",
    "                                                    # We'll use it as a starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo): Create the list of the most popular movies\n",
    "\n",
    "- Here, popular is the number of times the movie appears in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356, 318, 296, 593, 2571, 260, 480, 110, 589, 527]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# We can sum Counter objects -> values from matching keys are summed\n",
    "counts = np.asarray([Counter(seq) for seq in sequences_of_movies]).sum()\n",
    "most_popular = list(dict(counts.most_common()).keys())\n",
    "num_items = len(most_popular)\n",
    "\n",
    "# We check what the first 10 most popular movies look like\n",
    "print(most_popular[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "#Most popular looks like this:\n",
    "[356,318,296,2571,593,260,480,110,589,...]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec skip-gram <=> Prod2Vec\n",
    "\n",
    "\n",
    "### Word2Vec\n",
    "\n",
    "The MAIN idea of word2vec is to maximise the similarity (dot product) between the vectors for words which appear close together (in the context of each other) in text, and minimise the similarity of words that do not. \n",
    "\n",
    "This can be applied to products instead of words: it clusters similar products together.\n",
    "\n",
    "\n",
    "#### Paper Abstract:\n",
    "> In recent years online advertising has become increasingly ubiquitous and effective. Advertisements shown to visitors fund sites and apps that publish digital content, manage social networks, and operate e-mail services. Given such large variety of internet resources, determining an appropriate type of advertising for a given platform has become critical to financial success. Native advertisements, namely ads that are similar in look and feel to content, have had great success in news and social feeds. However, to date there has not been a winning formula for ads in e-mail clients. In this paper we describe a system that leverages user purchase history determined from e-mail receipts to deliver highly personalized product ads to Yahoo Mail users. We propose to use a novel neural language-based algorithm specifically tailored for delivering effective product recommendations, which was evaluated against baselines that included showing popular products and products predicted based on co-occurrence. We conducted rigorous offline testing using a large-scale product purchase data set, covering purchases of more than 29 million users from 172 e-commerce websites. Ads in the form of product recommendations were successfully tested on online traffic, where we observed a steady 9% lift in click-through rates over other ad formats in mail, as well as comparable lift in conversion rates. Following successful tests, the system was launched into production during the holiday season of 2014\n",
    "\n",
    "[Prod2Vec Model](https://arxiv.org/abs/1606.07154)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim has the best python implementation of word2vec's algorithms:\n",
    "\n",
    "We can just use these raw implementations. The only thing to do is to consider items as words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 16:29:51,301 : INFO : collecting all words and their counts\n",
      "2022-04-29 16:29:51,302 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-04-29 16:29:51,313 : INFO : collected 9616 word types from a corpus of 97786 raw words and 610 sentences\n",
      "2022-04-29 16:29:51,314 : INFO : Creating a fresh vocabulary\n",
      "2022-04-29 16:29:51,337 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 9616 unique words (100.0%% of original 9616, drops 0)', 'datetime': '2022-04-29T16:29:51.337484', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-29 16:29:51,339 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 97786 word corpus (100.0%% of original 97786, drops 0)', 'datetime': '2022-04-29T16:29:51.339985', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-29 16:29:51,384 : INFO : deleting the raw counts dictionary of 9616 items\n",
      "2022-04-29 16:29:51,385 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2022-04-29 16:29:51,385 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 97657.99863393226 word corpus (99.9%% of prior 97786)', 'datetime': '2022-04-29T16:29:51.385994', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-29 16:29:51,460 : INFO : estimated required memory for 9616 words and 50 dimensions: 8654400 bytes\n",
      "2022-04-29 16:29:51,461 : INFO : resetting layer weights\n",
      "2022-04-29 16:29:51,463 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-04-29T16:29:51.463506', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'build_vocab'}\n",
      "2022-04-29 16:29:51,463 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 9616 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2022-04-29T16:29:51.463506', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'train'}\n",
      "2022-04-29 16:29:51,808 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:51,826 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:51,835 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:51,836 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:51,839 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:51,842 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:51,843 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:51,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:51,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:51,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:51,876 : INFO : EPOCH - 1 : training on 97786 raw words (97686 effective words) took 0.4s, 239044 effective words/s\n",
      "2022-04-29 16:29:52,225 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:52,239 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:52,240 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:52,250 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:52,251 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:52,253 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:52,254 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:52,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:52,262 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:52,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:52,264 : INFO : EPOCH - 2 : training on 97786 raw words (97658 effective words) took 0.4s, 253905 effective words/s\n",
      "2022-04-29 16:29:52,606 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:52,611 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:52,621 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:52,625 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:52,631 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:52,634 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:52,636 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:52,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:52,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:52,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:52,642 : INFO : EPOCH - 3 : training on 97786 raw words (97675 effective words) took 0.4s, 260808 effective words/s\n",
      "2022-04-29 16:29:52,972 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:52,982 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:52,990 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:52,997 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:53,007 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:53,009 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:53,009 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:53,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:53,010 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:53,010 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:53,011 : INFO : EPOCH - 4 : training on 97786 raw words (97642 effective words) took 0.4s, 267146 effective words/s\n",
      "2022-04-29 16:29:53,352 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:53,353 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:53,360 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:53,371 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:53,373 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:53,374 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:53,379 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:53,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:53,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:53,396 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:53,397 : INFO : EPOCH - 5 : training on 97786 raw words (97659 effective words) took 0.4s, 255487 effective words/s\n",
      "2022-04-29 16:29:53,735 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:53,751 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:53,753 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:53,759 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:53,764 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:53,766 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:53,771 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:53,772 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:53,772 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:53,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:53,774 : INFO : EPOCH - 6 : training on 97786 raw words (97657 effective words) took 0.4s, 261384 effective words/s\n",
      "2022-04-29 16:29:54,120 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:54,126 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:54,127 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:54,128 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:54,137 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:54,138 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:54,143 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:54,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:54,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:54,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:54,150 : INFO : EPOCH - 7 : training on 97786 raw words (97665 effective words) took 0.4s, 261739 effective words/s\n",
      "2022-04-29 16:29:54,485 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:54,503 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:54,513 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:54,515 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:54,518 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:54,521 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:54,526 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:54,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:54,530 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:54,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:54,533 : INFO : EPOCH - 8 : training on 97786 raw words (97673 effective words) took 0.4s, 257196 effective words/s\n",
      "2022-04-29 16:29:54,875 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:54,884 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:54,884 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:54,892 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:54,901 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:54,901 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:54,904 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:54,905 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:54,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:54,909 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:54,909 : INFO : EPOCH - 9 : training on 97786 raw words (97638 effective words) took 0.4s, 262247 effective words/s\n",
      "2022-04-29 16:29:55,242 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:55,252 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:55,257 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:55,261 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:55,264 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:55,266 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:55,269 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:55,276 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:55,279 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:55,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:55,279 : INFO : EPOCH - 10 : training on 97786 raw words (97656 effective words) took 0.4s, 266296 effective words/s\n",
      "2022-04-29 16:29:55,617 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:55,628 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:55,629 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:55,629 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:55,633 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:55,636 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:55,640 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:55,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:55,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:55,650 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:55,651 : INFO : EPOCH - 11 : training on 97786 raw words (97652 effective words) took 0.4s, 265613 effective words/s\n",
      "2022-04-29 16:29:55,984 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:55,996 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:56,001 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:56,009 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:56,013 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:56,014 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:56,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:56,018 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:56,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:56,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:56,023 : INFO : EPOCH - 12 : training on 97786 raw words (97660 effective words) took 0.4s, 265172 effective words/s\n",
      "2022-04-29 16:29:56,359 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:56,374 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:56,379 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:56,383 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:56,385 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:56,389 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:56,390 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:56,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:56,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:56,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:56,395 : INFO : EPOCH - 13 : training on 97786 raw words (97653 effective words) took 0.4s, 264684 effective words/s\n",
      "2022-04-29 16:29:56,731 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:56,742 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:56,749 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:56,756 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:56,757 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:56,757 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:56,760 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:56,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:56,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:56,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:56,768 : INFO : EPOCH - 14 : training on 97786 raw words (97664 effective words) took 0.4s, 264133 effective words/s\n",
      "2022-04-29 16:29:57,117 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:57,121 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:57,134 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:57,136 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:57,143 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:57,144 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:57,144 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:57,147 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:57,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:57,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:57,150 : INFO : EPOCH - 15 : training on 97786 raw words (97655 effective words) took 0.4s, 258656 effective words/s\n",
      "2022-04-29 16:29:57,486 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:57,510 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:57,512 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:57,515 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:57,520 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:57,522 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:57,523 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:57,526 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:57,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:57,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:57,529 : INFO : EPOCH - 16 : training on 97786 raw words (97667 effective words) took 0.4s, 260309 effective words/s\n",
      "2022-04-29 16:29:57,861 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:57,864 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:57,877 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:57,880 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:57,883 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:57,887 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:57,888 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:57,888 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:57,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:57,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:57,895 : INFO : EPOCH - 17 : training on 97786 raw words (97675 effective words) took 0.4s, 270021 effective words/s\n",
      "2022-04-29 16:29:58,246 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:58,255 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:58,269 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:58,275 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:58,278 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:58,280 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:58,281 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:58,285 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:58,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:58,303 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:58,304 : INFO : EPOCH - 18 : training on 97786 raw words (97662 effective words) took 0.4s, 241489 effective words/s\n",
      "2022-04-29 16:29:58,656 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:58,657 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:58,668 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:58,670 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:58,677 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:58,680 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:58,683 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:58,684 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:58,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:58,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:58,687 : INFO : EPOCH - 19 : training on 97786 raw words (97663 effective words) took 0.4s, 257284 effective words/s\n",
      "2022-04-29 16:29:59,032 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:59,044 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:59,045 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:59,045 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:59,049 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:59,052 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:59,056 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:59,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:59,058 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:59,060 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:59,061 : INFO : EPOCH - 20 : training on 97786 raw words (97657 effective words) took 0.4s, 263669 effective words/s\n",
      "2022-04-29 16:29:59,440 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:59,451 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:59,454 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:59,458 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:59,467 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:59,468 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:59,471 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:59,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:59,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:59,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:59,476 : INFO : EPOCH - 21 : training on 97786 raw words (97649 effective words) took 0.4s, 237423 effective words/s\n",
      "2022-04-29 16:29:59,817 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:29:59,828 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:29:59,836 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:29:59,838 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:29:59,846 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:29:59,851 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:29:59,852 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:29:59,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:29:59,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:29:59,857 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:29:59,857 : INFO : EPOCH - 22 : training on 97786 raw words (97663 effective words) took 0.4s, 258719 effective words/s\n",
      "2022-04-29 16:30:00,196 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:00,215 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:00,218 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:00,229 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:00,234 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:00,239 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:00,240 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:00,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:00,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:00,244 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:00,244 : INFO : EPOCH - 23 : training on 97786 raw words (97684 effective words) took 0.4s, 254793 effective words/s\n",
      "2022-04-29 16:30:00,604 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:00,605 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:00,613 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:00,620 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:00,623 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:00,625 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:00,626 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:00,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:00,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:00,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:00,634 : INFO : EPOCH - 24 : training on 97786 raw words (97634 effective words) took 0.4s, 253382 effective words/s\n",
      "2022-04-29 16:30:00,995 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:01,002 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:01,011 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:01,013 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:01,018 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:01,020 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:01,021 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:01,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:01,025 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:01,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:01,027 : INFO : EPOCH - 25 : training on 97786 raw words (97666 effective words) took 0.4s, 251055 effective words/s\n",
      "2022-04-29 16:30:01,378 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:01,379 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:01,386 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:01,398 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:01,401 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:01,404 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:01,406 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:01,407 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:01,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:01,408 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:01,409 : INFO : EPOCH - 26 : training on 97786 raw words (97662 effective words) took 0.4s, 258506 effective words/s\n",
      "2022-04-29 16:30:01,753 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:01,767 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:01,772 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:01,779 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:01,783 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:01,784 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:01,787 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:01,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:01,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:01,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:01,797 : INFO : EPOCH - 27 : training on 97786 raw words (97667 effective words) took 0.4s, 254017 effective words/s\n",
      "2022-04-29 16:30:02,165 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:02,167 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:02,184 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:02,189 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:02,191 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:02,200 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:02,202 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:02,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:02,212 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:02,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:02,214 : INFO : EPOCH - 28 : training on 97786 raw words (97676 effective words) took 0.4s, 235914 effective words/s\n",
      "2022-04-29 16:30:02,573 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:02,575 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:02,584 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:02,599 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:02,603 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:02,603 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:02,604 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:02,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:02,608 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:02,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:02,609 : INFO : EPOCH - 29 : training on 97786 raw words (97649 effective words) took 0.4s, 250433 effective words/s\n",
      "2022-04-29 16:30:02,968 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:02,974 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:02,986 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:02,991 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:02,994 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:02,996 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:03,000 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:03,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:03,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:03,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:03,005 : INFO : EPOCH - 30 : training on 97786 raw words (97652 effective words) took 0.4s, 252612 effective words/s\n",
      "2022-04-29 16:30:03,397 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:03,398 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:03,400 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:03,408 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:03,415 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:03,421 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:03,424 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:03,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:03,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:03,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:03,438 : INFO : EPOCH - 31 : training on 97786 raw words (97660 effective words) took 0.4s, 227553 effective words/s\n",
      "2022-04-29 16:30:03,812 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:03,815 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:03,821 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:03,826 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:03,830 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:03,836 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:03,844 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:03,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:03,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:03,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:03,848 : INFO : EPOCH - 32 : training on 97786 raw words (97663 effective words) took 0.4s, 240339 effective words/s\n",
      "2022-04-29 16:30:04,221 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:04,222 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:04,232 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:04,238 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:04,244 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:04,245 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:04,247 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:04,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:04,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:04,254 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:04,255 : INFO : EPOCH - 33 : training on 97786 raw words (97653 effective words) took 0.4s, 242453 effective words/s\n",
      "2022-04-29 16:30:04,623 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:04,637 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:04,640 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:04,640 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:04,647 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:04,650 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:04,652 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:04,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:04,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:04,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:04,658 : INFO : EPOCH - 34 : training on 97786 raw words (97658 effective words) took 0.4s, 244294 effective words/s\n",
      "2022-04-29 16:30:05,009 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:05,014 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:05,026 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:05,027 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:05,031 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:05,033 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:05,037 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:05,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:05,041 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:05,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:05,048 : INFO : EPOCH - 35 : training on 97786 raw words (97650 effective words) took 0.4s, 253224 effective words/s\n",
      "2022-04-29 16:30:05,395 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:05,406 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:05,415 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:05,418 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:05,424 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:05,426 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:05,426 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:05,428 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:05,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:05,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:05,433 : INFO : EPOCH - 36 : training on 97786 raw words (97659 effective words) took 0.4s, 255799 effective words/s\n",
      "2022-04-29 16:30:05,798 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:05,805 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:05,806 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:05,819 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:05,821 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:05,825 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:05,826 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:05,832 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:05,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:05,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:05,843 : INFO : EPOCH - 37 : training on 97786 raw words (97678 effective words) took 0.4s, 240311 effective words/s\n",
      "2022-04-29 16:30:06,188 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:06,190 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:06,194 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:06,204 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:06,208 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:06,210 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:06,210 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:06,211 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:06,213 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:06,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:06,220 : INFO : EPOCH - 38 : training on 97786 raw words (97678 effective words) took 0.4s, 262250 effective words/s\n",
      "2022-04-29 16:30:06,565 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:06,576 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:06,582 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:06,582 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:06,585 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:06,594 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:06,594 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:06,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:06,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:06,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:06,599 : INFO : EPOCH - 39 : training on 97786 raw words (97658 effective words) took 0.4s, 260199 effective words/s\n",
      "2022-04-29 16:30:06,947 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:06,956 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:06,966 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:06,968 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:06,973 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:06,974 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:06,979 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:06,980 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:06,981 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:06,981 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:06,982 : INFO : EPOCH - 40 : training on 97786 raw words (97652 effective words) took 0.4s, 257302 effective words/s\n",
      "2022-04-29 16:30:07,336 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:07,337 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:07,345 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:07,348 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:07,359 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:07,360 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:07,362 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:07,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:07,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:07,372 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:07,372 : INFO : EPOCH - 41 : training on 97786 raw words (97651 effective words) took 0.4s, 252274 effective words/s\n",
      "2022-04-29 16:30:07,717 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:07,727 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:07,735 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:07,738 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:07,744 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:07,745 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:07,746 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:07,747 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:07,747 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:07,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:07,749 : INFO : EPOCH - 42 : training on 97786 raw words (97658 effective words) took 0.4s, 261539 effective words/s\n",
      "2022-04-29 16:30:08,093 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:08,099 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:08,117 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:08,118 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:08,120 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:08,122 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:08,124 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:08,125 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:08,125 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:08,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:08,126 : INFO : EPOCH - 43 : training on 97786 raw words (97627 effective words) took 0.4s, 261372 effective words/s\n",
      "2022-04-29 16:30:08,465 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:08,468 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:08,492 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:08,494 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:08,508 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:08,528 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:08,533 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:08,534 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:08,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:08,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:08,539 : INFO : EPOCH - 44 : training on 97786 raw words (97665 effective words) took 0.4s, 239301 effective words/s\n",
      "2022-04-29 16:30:08,885 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:08,889 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:08,896 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:08,903 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:08,903 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:08,908 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:08,908 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:08,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:08,916 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:08,921 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:08,922 : INFO : EPOCH - 45 : training on 97786 raw words (97661 effective words) took 0.4s, 257185 effective words/s\n",
      "2022-04-29 16:30:09,263 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:09,274 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:09,278 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:09,288 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:09,290 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:09,296 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:09,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:09,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:09,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:09,300 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:09,301 : INFO : EPOCH - 46 : training on 97786 raw words (97640 effective words) took 0.4s, 261400 effective words/s\n",
      "2022-04-29 16:30:09,648 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:09,649 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:09,663 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:09,669 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:09,670 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:09,671 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:09,674 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:09,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:09,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:09,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:09,682 : INFO : EPOCH - 47 : training on 97786 raw words (97665 effective words) took 0.4s, 258688 effective words/s\n",
      "2022-04-29 16:30:10,024 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:10,026 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:10,040 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:10,048 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:10,049 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:10,050 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:10,054 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:10,055 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:10,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:10,058 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:10,058 : INFO : EPOCH - 48 : training on 97786 raw words (97671 effective words) took 0.4s, 261716 effective words/s\n",
      "2022-04-29 16:30:10,402 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:10,416 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:10,419 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:10,422 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:10,427 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:10,428 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:10,434 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:10,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:10,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:10,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:10,441 : INFO : EPOCH - 49 : training on 97786 raw words (97653 effective words) took 0.4s, 258288 effective words/s\n",
      "2022-04-29 16:30:10,787 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 16:30:10,788 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 16:30:10,801 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 16:30:10,801 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 16:30:10,812 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 16:30:10,813 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 16:30:10,815 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 16:30:10,816 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 16:30:10,819 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 16:30:10,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 16:30:10,821 : INFO : EPOCH - 50 : training on 97786 raw words (97669 effective words) took 0.4s, 259914 effective words/s\n",
      "2022-04-29 16:30:10,821 : INFO : Word2Vec lifecycle event {'msg': 'training on 4889300 raw words (4882988 effective words) took 19.4s, 252251 effective words/s', 'datetime': '2022-04-29T16:30:10.821908', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'train'}\n",
      "2022-04-29 16:30:10,822 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=9616, vector_size=50, alpha=0.025)', 'datetime': '2022-04-29T16:30:10.822410', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "train_seq_str = [list(map(str,seq)) for seq in train_seq] # we just say that our items id's are strings..\n",
    "    \n",
    "\n",
    "# the following configuration is the default configuration\n",
    "# At first, the init method got the unexpected keyword arguments \"size\" and \"iter\"\n",
    "# By checking the documentation, we can find that the \"size\" argument is now called \"vector_size\" and\n",
    "# that \"iter\" is now called \"epochs\"\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=train_seq_str,\n",
    "                                vector_size=50, window=10,               ### here we train a cbow model \n",
    "                                min_count=0,                      \n",
    "                                sample=0.001, ns_exponent=0.75, workers=10,\n",
    "                                sg=1, hs=0, negative=15,          ### set sg to 1 to train a sg model => Prod2Vec\n",
    "                                cbow_mean=0,\n",
    "                                epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0074254e-01 -6.4518154e-01 -1.9506796e-01  3.7094378e-01\n",
      " -5.3686053e-01 -2.0066336e-01  7.6492526e-02 -4.5271805e-01\n",
      " -6.3443112e-01 -5.9595663e-02 -1.6577612e-01 -6.4148939e-01\n",
      " -2.9267016e-01  4.8130924e-01  5.4462796e-01  7.8360009e-01\n",
      "  1.7059387e-01 -1.3491103e-01 -2.9239038e-01 -3.2902139e-01\n",
      " -5.0423551e-01  2.9892731e-01  1.7792910e-01 -6.2749010e-01\n",
      " -3.3014727e-01  7.9042345e-01 -2.7299440e-01 -1.7648122e-01\n",
      "  4.0832553e-02  4.4780809e-01 -1.8865852e-01  1.1530963e-02\n",
      "  5.9730673e-01 -1.2696083e-01 -1.7503755e-01 -1.8936023e-01\n",
      " -6.0698751e-02 -6.2536383e-01  2.8162514e-04  2.0446047e-02\n",
      "  5.4630548e-01 -4.3348706e-01 -1.0088697e-01  2.1373785e-01\n",
      "  1.1573187e-01 -6.2917203e-01  3.8120708e-01 -2.6983368e-01\n",
      " -6.1774734e-02  1.8207285e-01]\n",
      "356\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(w2v.wv.vectors[0])              # The vector of index 0\n",
    "\n",
    "# Again, when executing this node, we get an error. It seems like a few of the functions and attributs used have been replaced\n",
    "# in newer versions of gensim. The \"index2word\" attribute is now called \"index_to_key\"\n",
    "print(w2v.wv.index_to_key[0])           # codes for the movieId 356\n",
    "\n",
    "# The vocab \"attribute\" has been removed. We can use different attributes instead like :\n",
    "# KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val)\n",
    "# We now use the key_to_index attribute\n",
    "print(w2v.wv.key_to_index[\"356\"])      # Inverse mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Major note**\n",
    "\n",
    "As I have modified some of the functions used in order to make the code runnable again, I don't know if it will have any effects of the rest of the notebook but let's hope not. If any of the results seems strange or out of place, I will try to fix the code I've modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting similar items:\n",
    "\n",
    "The heart of the algorithm is in the similar item search. As in word2vec, we simply use cosine distance between items to find \"similar items\"\n",
    "\n",
    "### We can search by id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[231, 410, 292, 185, 434]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_ids(w2vmodel,iid,num=5):\n",
    "    \n",
    "    if str(iid) in w2vmodel.wv.index_to_key:\n",
    "        return [int(iid) for iid,_ in w2vmodel.wv.most_similar(str(iid),topn=num)] \n",
    "    else:\n",
    "        return []\n",
    "\n",
    "get_similar_ids(w2v,last_consumed_item[0],num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or by vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12833856, -0.9748843 , -0.588088  ,  0.1255272 , -0.37283424,\n",
       "       -0.3683326 , -0.582962  , -0.04290681, -0.52555585, -0.16514345,\n",
       "        0.22018643, -0.02168382, -1.0273906 ,  0.2903019 ,  0.9128572 ,\n",
       "        0.5097222 ,  0.1810354 , -0.23724912,  0.20306313, -0.5100846 ,\n",
       "       -0.12417614,  0.25936684,  0.22079636, -1.1885504 , -0.39398322,\n",
       "        0.47633925, -0.36126354, -0.19677164, -0.48905674,  0.9990013 ,\n",
       "        0.42597494,  0.5236524 ,  0.8724856 , -0.5313531 ,  0.16758032,\n",
       "       -0.41889164,  0.30819002, -0.65761197,  0.39206782, -0.02582163,\n",
       "        0.32290298, -0.48980114,  0.21802032,  0.18339832,  0.8385788 ,\n",
       "       -1.1030978 ,  0.07435931, -0.35324025, -0.18675724, -0.2055685 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv[str(last_consumed_item[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[339, 231, 410, 292, 185]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_similar_vectors(w2vmodel,vec,num=5):\n",
    "        return [int(iid) for iid,_ in w2vmodel.wv.most_similar(positive=[vec],topn=num)] \n",
    "\n",
    "get_similar_vectors(w2v,w2v.wv[str(last_consumed_item[0])],num=5) # items are strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see if this works\n",
    "\n",
    "We can query by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Toy Story (1995)\n",
      "\n",
      "-->  Forrest Gump (1994)\n",
      "-->  Toy Story 2 (1999)\n",
      "-->  Lion King, The (1994)\n"
     ]
    }
   ],
   "source": [
    "ID = 1\n",
    "NUM_SIM = 3\n",
    "\n",
    "print(\"Movies similar to: \", id2title[ID])\n",
    "print(\"\")\n",
    "for x in get_similar_ids(w2v,ID,NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query by vector\n",
    "\n",
    "**NOTE:** the 1st results can be the item(s) you've used to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Toy Story (1995)\n",
      "\n",
      "-->  Toy Story (1995)\n",
      "-->  Forrest Gump (1994)\n",
      "-->  Toy Story 2 (1999)\n",
      "-->  Lion King, The (1994)\n"
     ]
    }
   ],
   "source": [
    "ID = 1\n",
    "NUM_SIM = 4\n",
    "print(\"Movies similar to: \", id2title[ID])\n",
    "print(\"\")\n",
    "for x in get_similar_vectors(w2v,w2v.wv[str(ID)],NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result was the following (for ID = 1 & NUM_SIM = 3)\n",
    "\n",
    "Movies similar to:  Toy Story (1995)\n",
    ">-  Beauty and the Beast (1991)\n",
    ">-   Toy Story 2 (1999)\n",
    ">-   Lion King, The (1994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using vectors enables operations like additions to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Matrix, The (1999) + Terminator 2: Judgment Day (1991)\n",
      "\n",
      "-->  Matrix, The (1999)\n",
      "-->  Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "-->  Venom (1982)\n",
      "-->  Saving Private Ryan (1998)\n",
      "-->  Terminator, The (1984)\n",
      "-->  Terminator 2: Judgment Day (1991)\n",
      "-->  Sixth Sense, The (1999)\n",
      "-->  Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "-->  Die Hard (1988)\n",
      "-->  Gladiator (2000)\n"
     ]
    }
   ],
   "source": [
    "ID1 = 2571\n",
    "ID2 = 589\n",
    "NUM_SIM = 10\n",
    "\n",
    "vec = np.max([w2v.wv[str(ID1)],w2v.wv[str(ID2)]],axis=0)\n",
    "\n",
    "print(\"Movies similar to: \", id2title[ID1] , \"+\",  id2title[ID2] )\n",
    "print(\"\")\n",
    "for x in get_similar_vectors(w2v,vec ,NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with another combination of IDs and the same number of similar movies (10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to:  Dark Victory (1939) + Once Bitten (1985)\n",
      "\n",
      "-->  Once Bitten (1985)\n",
      "-->  Dark Victory (1939)\n",
      "-->  Unprecedented: The 2000 Presidential Election (2002)\n",
      "-->  Hotel Chevalier (Part 1 of 'The Darjeeling Limited') (2007)\n",
      "-->  Brave New World (1998)\n",
      "-->  Grand Hotel (1932)\n",
      "-->  I'm Here (2010)\n",
      "-->  Royal Wedding (1951)\n",
      "-->  Dr. Jekyll and Mr. Hyde (1931)\n",
      "-->  Jacket, The (2005)\n"
     ]
    }
   ],
   "source": [
    "# The IDs have been generated randomly from the most_popular list\n",
    "ID1 = most_popular[6759]\n",
    "ID2 = most_popular[3921]\n",
    "NUM_SIM = 10\n",
    "\n",
    "vec = np.max([w2v.wv[str(ID1)],w2v.wv[str(ID2)]],axis=0)\n",
    "\n",
    "print(\"Movies similar to: \", id2title[ID1] , \"+\",  id2title[ID2] )\n",
    "print(\"\")\n",
    "for x in get_similar_vectors(w2v,vec ,NUM_SIM):\n",
    "    print(\"--> \",id2title[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we now have a good base for our sequence recommendation algorithm, let's write something to evaluate our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Todo) write a `get_relevance_list(proposed_ids,real_ids)` function:\n",
    "\n",
    "This function will be used to compare proposed items w/ real items:\n",
    "\n",
    "\n",
    "- A relevant item is an item which is in the ground truth\n",
    "- It returns a list which length is the number of proposed items filled of 0's and 1's : 0 means the item is not relevant, 1 means it's relevant.\n",
    "\n",
    "- get_relevance_list([1,2,3,4],[1,4,5,6]) should returns [1,0,0,1]  because items 1 and 4 are relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_relevance_list(proposed_ids,real_ids):\n",
    "    real_ids = set(real_ids)\n",
    "    return [1 if x in real_ids else 0 for x in proposed_ids]\n",
    "get_relevance_list([1,2,3,4],[1,4,5,6]) #returns [1,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test our function on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevance_list(most_popular[:25],test_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevance_list(get_similar_ids(w2v,last_consumed_item[0],25),test_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, now, let's write prediction funtions:\n",
    "\n",
    "- `predict_pop` will recommend the k's most popular items\n",
    "- `predict_w2v` will recommend the k's most similar items to the last one consumed\n",
    "\n",
    "#### (TODO) : complete those functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pop(last_seen,k):\n",
    "    # Here the last_seen argument is useless as we only return the most popular movies\n",
    "    return most_popular[:k]\n",
    "\n",
    "def predict_w2v(last_seen,k):\n",
    "    return get_similar_ids(w2v, last_seen, k)\n",
    "\n",
    "#data is list of last_consumed:\n",
    "def get_predictions(predict_func,data,truth,k=5):\n",
    "    if k == -1 or k == 0:\n",
    "        k = num_items\n",
    "    return [get_relevance_list(predict_func(last_seen,k),will_see) for last_seen,will_see in zip(data,truth)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The `get_predictions(...)` function returns the relevant list associated to predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cells should return list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
      "[[0, 0, 0], [0, 0, 1], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(get_predictions(predict_pop,last_consumed_item[:5],test_seq[:5],3))\n",
    "print(get_predictions(predict_w2v,last_consumed_item[:5],test_seq[:5],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected output: \n",
    "```\n",
    "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The return of the MRR and nDCG functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "4.2618595071429155\n"
     ]
    }
   ],
   "source": [
    "test_list = [[0,0,1],[0,1,0],[1,0,0],[0,0,0]]\n",
    "\n",
    "def rr(list_items):\n",
    "    relevant_indexes = np.asarray(list_items).nonzero()[0]\n",
    "    \n",
    "    if len(relevant_indexes) > 0:\n",
    "        return 1/(relevant_indexes[0]+1) # arrays are indexed from 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mrr(list_list_items):\n",
    "    return np.mean([rr(list_item) for list_item in list_list_items])\n",
    "\n",
    "mrr(test_list) #0.4583333333333333\n",
    "\n",
    "# The dcg@k is the sum of the relevance, penalized gradually\n",
    "def dcg_at_k(r, k):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        \n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        \n",
    "    return 0.\n",
    "\n",
    "# test values\n",
    "# r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "# dcg_at_k(r, 1) => 3.0\n",
    "# dcg_at_k(r, 2) => 4.2618595071429155\n",
    "r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "print(dcg_at_k(r, 1))\n",
    "print(dcg_at_k(r, 2))\n",
    "\n",
    "def mean_dcg(rel_lists,k):\n",
    "    return np.mean([dcg_at_k(rel_list,k) for rel_list in rel_lists])\n",
    "\n",
    "# And it's normalized version\n",
    "def ndcg_at_k(r, k):\n",
    "    \"\"\"\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "    \"\"\"\n",
    "    dcg_max =  dcg_at_k(sorted(r)[::-1],k) \n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k) / dcg_max\n",
    "\n",
    "# test values\n",
    "# r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "# ndcg_at_k(r, 1) => 1.0\n",
    "# ndcg_at_k(r, 4) => 0.794285\n",
    "    \n",
    "r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]    \n",
    "ndcg_at_k(r, 4)\n",
    "\n",
    "def mean_ndcg(rel_lists,k):\n",
    "    return np.mean([ndcg_at_k(rel_list,k) for rel_list in rel_lists])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how this naÃ¯ve way of predicting items to show works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/MRR\n",
      "17.87234931650308\n",
      "11.694294147313169\n",
      "\n",
      "DCG\n",
      "0.051054704276776476\n",
      "0.08992996018517257\n",
      "\n",
      "nDCG\n",
      "0.017315723982695277\n",
      "0.030900502616531756\n"
     ]
    }
   ],
   "source": [
    "pop_preds = get_predictions(predict_pop,last_consumed_item,test_seq,-1)\n",
    "w2v_preds = get_predictions(predict_w2v,last_consumed_item,test_seq,-1)\n",
    "\n",
    "print(\"1/MRR\")\n",
    "print(1/mrr(pop_preds))\n",
    "print(1/mrr(w2v_preds))\n",
    "print(\"\")\n",
    "print(\"DCG\")\n",
    "print(mean_dcg(pop_preds,5))\n",
    "print(mean_dcg(w2v_preds,5))\n",
    "print(\"\")\n",
    "print(\"nDCG\")\n",
    "print(mean_ndcg(pop_preds,5))\n",
    "print(mean_ndcg(w2v_preds,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Can we do better ?\n",
    "\n",
    "Now, try a different strategy: \n",
    "\n",
    "\n",
    "- History should be discarded from prediction\n",
    "- Instead of basing the prediction on the last seen item, we'll take all the `seen[-n:]` ones (horizon) into account\n",
    "- To aggregate all items, we'll simply take the min rank to take into account the history offset.\n",
    "- Equal scores can be handled using the history offset.\n",
    "Example: \n",
    "\n",
    "> Let's say you chose to use the two last seen items `[item 44, Item 398]` to predict the following items\n",
    "\n",
    "Therefore, using `get_similar_ids` method on both items will yield two lists of **similar** ranked item id's:\n",
    " - Similar to item 44: `[item 1, item 33, item 5]`\n",
    " - Similar to item 398: `[item 25, item 1, item 5]`\n",
    " scores (rank,offset):\n",
    " ```\n",
    " scores := {item 1: (0,0), item 33: (1,0), item 5: (2,0) , item 25: (0,1)}```\n",
    " \n",
    " \n",
    "Then, aggregation by best rank should yield: `[1,25,33,5]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.833507857440182\n",
      "0.06765394054546285\n",
      "0.023082468573992283\n"
     ]
    }
   ],
   "source": [
    "def predict_max_w2v(seen,k,horizon=2):\n",
    "    # We first have to get the last seen movies depending on the horizon and a score dictionnary\n",
    "    last_seen = seen[-horizon:]\n",
    "    scores = dict()\n",
    "    \n",
    "    # We now iterate on the last seen movies\n",
    "    for rank in range(len(last_seen)) :\n",
    "        # We predict the movies based on the last seen one\n",
    "        pred_sim = get_similar_ids(w2v, last_seen[rank], k)\n",
    "\n",
    "        # We now iterate on the predicted ids\n",
    "        for offset in range(len(pred_sim)) :\n",
    "            item = pred_sim[offset]\n",
    "\n",
    "            # We now save the scores in the dictionnary depending on the rank and the offset\n",
    "            # We only save the scores one time for each time (in case they appear multiple times)\n",
    "            if item not in scores.keys() :\n",
    "                scores[item] = (rank, offset)\n",
    "    \n",
    "    # We now return a list of the items ordered by the rank\n",
    "    return list(dict(sorted(scores.items(), key=lambda item: item[1])).keys())\n",
    "\n",
    "\n",
    "w2v_best_preds = get_predictions(predict_max_w2v,train_seq,test_seq,-1)\n",
    "\n",
    "print(1/mrr(w2v_best_preds))\n",
    "print(mean_dcg(w2v_best_preds,5))\n",
    "print(mean_ndcg(w2v_best_preds,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Not really better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize learned embeddings\n",
    "\n",
    "Just like in the 1st practical, we propose to visualize learnt items embeddings with the [Tensorflow projector](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function saves embeddings (a numpy array) and associated labels into tsv files.\n",
    "\n",
    "def save_embeddings(embs,dict_label,path=\"saved_word_vectors\"):\n",
    "    \"\"\"\n",
    "    embs is Numpy.array(N,size)\n",
    "    dict_label is {str(word)->int(idx)} or {int(idx)->str(word)}\n",
    "    \"\"\"\n",
    "    def int_first(k,v):\n",
    "        if type(k) == int:\n",
    "            return (k,v)\n",
    "        else:\n",
    "            return (v,k)\n",
    "\n",
    "    np.savetxt(f\"{path}_vectors.tsv\", embs, delimiter=\"\\t\")\n",
    "\n",
    "    #labels \n",
    "    if dict_label:\n",
    "        sorted_labs = np.array([lab for idx,lab in sorted([int_first(k,v) for k,v in dict_label.items()])])\n",
    "        print(sorted_labs)\n",
    "        with open(f\"{path}_metadata.tsv\",\"w\") as metadata_file:\n",
    "            for x in sorted_labs: #hack for space\n",
    "                if len(x.strip()) == 0:\n",
    "                    x = f\"space-{len(x)}\"\n",
    "                    \n",
    "                metadata_file.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2title = {i:id2title[int(mid)] for i,mid in enumerate(w2v.wv.index_to_key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Forrest Gump (1994)' 'Shawshank Redemption, The (1994)'\n",
      " 'Pulp Fiction (1994)' ... 'Little Miss Marker (1980)'\n",
      " 'Late Marriage (Hatuna Meuheret) (2001)'\n",
      " 'Andrew Dice Clay: Dice Rules (1991)']\n"
     ]
    }
   ],
   "source": [
    "save_embeddings(w2v.wv.vectors,vec2title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two new files, \"saved_word_vectors_metadata.tsv\" and \"saved_word_vectors_metadata.tsv\". Let's quickly check what's inside of these files.\n",
    "\n",
    "Note - For some reason, I had to delete the last empty row from the metadata file in order to make it usable with the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forrest Gump (1994)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9610</th>\n",
       "      <td>Facing Windows (Finestra di fronte, La) (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>Eighth Day, The (Huitiï¿½me jour, Le) (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9612</th>\n",
       "      <td>Little Miss Marker (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>Late Marriage (Hatuna Meuheret) (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9614</th>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9615 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Forrest Gump (1994)\n",
       "0                   Shawshank Redemption, The (1994)\n",
       "1                                Pulp Fiction (1994)\n",
       "2                                 Matrix, The (1999)\n",
       "3                   Silence of the Lambs, The (1991)\n",
       "4          Star Wars: Episode IV - A New Hope (1977)\n",
       "...                                              ...\n",
       "9610  Facing Windows (Finestra di fronte, La) (2003)\n",
       "9611      Eighth Day, The (Huitiï¿½me jour, Le) (1996)\n",
       "9612                       Little Miss Marker (1980)\n",
       "9613          Late Marriage (Hatuna Meuheret) (2001)\n",
       "9614             Andrew Dice Clay: Dice Rules (1991)\n",
       "\n",
       "[9615 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the pandas library in order to read the files (tsv files are similar to csv files)\n",
    "pd.read_csv(\"saved_word_vectors_metadata.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1.308204531669616699e-01</th>\n",
       "      <th>-9.373525977134704590e-01</th>\n",
       "      <th>-1.903456151485443115e-01</th>\n",
       "      <th>8.866167664527893066e-01</th>\n",
       "      <th>-2.364774942398071289e-01</th>\n",
       "      <th>-4.611333608627319336e-01</th>\n",
       "      <th>-3.990370035171508789e-01</th>\n",
       "      <th>4.677708260715007782e-03</th>\n",
       "      <th>-1.037948727607727051e+00</th>\n",
       "      <th>-4.934164285659790039e-01</th>\n",
       "      <th>...</th>\n",
       "      <th>4.002290666103363037e-01</th>\n",
       "      <th>-6.634631752967834473e-01</th>\n",
       "      <th>-4.466506242752075195e-01</th>\n",
       "      <th>4.443196654319763184e-01</th>\n",
       "      <th>2.412061840295791626e-01</th>\n",
       "      <th>-3.203268349170684814e-01</th>\n",
       "      <th>5.735866725444793701e-02</th>\n",
       "      <th>-1.806772649288177490e-01</th>\n",
       "      <th>-1.404088884592056274e-01</th>\n",
       "      <th>2.504607439041137695e-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191728</td>\n",
       "      <td>-0.337386</td>\n",
       "      <td>-0.133508</td>\n",
       "      <td>0.583781</td>\n",
       "      <td>0.054748</td>\n",
       "      <td>-0.359095</td>\n",
       "      <td>-0.285114</td>\n",
       "      <td>-0.410546</td>\n",
       "      <td>-1.203608</td>\n",
       "      <td>-0.559385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016586</td>\n",
       "      <td>-0.961386</td>\n",
       "      <td>0.080649</td>\n",
       "      <td>0.595540</td>\n",
       "      <td>0.835402</td>\n",
       "      <td>-0.125174</td>\n",
       "      <td>0.412031</td>\n",
       "      <td>-0.797428</td>\n",
       "      <td>-0.610982</td>\n",
       "      <td>0.626047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.666284</td>\n",
       "      <td>0.405146</td>\n",
       "      <td>0.261234</td>\n",
       "      <td>0.966058</td>\n",
       "      <td>-0.186964</td>\n",
       "      <td>-0.124168</td>\n",
       "      <td>0.119240</td>\n",
       "      <td>0.573752</td>\n",
       "      <td>-0.516475</td>\n",
       "      <td>-0.772345</td>\n",
       "      <td>...</td>\n",
       "      <td>1.760169</td>\n",
       "      <td>-0.822677</td>\n",
       "      <td>-1.047733</td>\n",
       "      <td>1.061342</td>\n",
       "      <td>-0.173978</td>\n",
       "      <td>-0.848040</td>\n",
       "      <td>0.719524</td>\n",
       "      <td>-0.480560</td>\n",
       "      <td>0.090974</td>\n",
       "      <td>0.356793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082193</td>\n",
       "      <td>-0.953947</td>\n",
       "      <td>0.041595</td>\n",
       "      <td>0.446591</td>\n",
       "      <td>0.255977</td>\n",
       "      <td>-0.500937</td>\n",
       "      <td>0.635074</td>\n",
       "      <td>1.076976</td>\n",
       "      <td>-1.133167</td>\n",
       "      <td>-0.281876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.177377</td>\n",
       "      <td>-0.482142</td>\n",
       "      <td>0.625845</td>\n",
       "      <td>0.280632</td>\n",
       "      <td>0.309906</td>\n",
       "      <td>-0.222284</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>-0.852292</td>\n",
       "      <td>-0.221956</td>\n",
       "      <td>0.398970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151991</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>-0.415382</td>\n",
       "      <td>0.517119</td>\n",
       "      <td>0.114304</td>\n",
       "      <td>0.106529</td>\n",
       "      <td>-0.197031</td>\n",
       "      <td>0.141737</td>\n",
       "      <td>-1.134646</td>\n",
       "      <td>-0.624014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848399</td>\n",
       "      <td>-0.904153</td>\n",
       "      <td>-0.054174</td>\n",
       "      <td>0.541750</td>\n",
       "      <td>0.535916</td>\n",
       "      <td>-0.321128</td>\n",
       "      <td>0.732958</td>\n",
       "      <td>-0.565319</td>\n",
       "      <td>-0.470649</td>\n",
       "      <td>0.639322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412334</td>\n",
       "      <td>-0.637332</td>\n",
       "      <td>-0.116872</td>\n",
       "      <td>0.365549</td>\n",
       "      <td>-0.076938</td>\n",
       "      <td>-0.705615</td>\n",
       "      <td>-0.593116</td>\n",
       "      <td>-0.198439</td>\n",
       "      <td>-0.859540</td>\n",
       "      <td>-0.925937</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011723</td>\n",
       "      <td>0.839060</td>\n",
       "      <td>0.433474</td>\n",
       "      <td>0.125990</td>\n",
       "      <td>0.484771</td>\n",
       "      <td>-0.472632</td>\n",
       "      <td>0.437122</td>\n",
       "      <td>-1.083687</td>\n",
       "      <td>0.757188</td>\n",
       "      <td>0.826228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9610</th>\n",
       "      <td>-0.014765</td>\n",
       "      <td>-0.089912</td>\n",
       "      <td>-0.059354</td>\n",
       "      <td>0.109058</td>\n",
       "      <td>-0.114996</td>\n",
       "      <td>-0.218520</td>\n",
       "      <td>-0.085448</td>\n",
       "      <td>0.297680</td>\n",
       "      <td>-0.398717</td>\n",
       "      <td>-0.181221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491519</td>\n",
       "      <td>-0.310350</td>\n",
       "      <td>0.096876</td>\n",
       "      <td>0.256428</td>\n",
       "      <td>0.243989</td>\n",
       "      <td>-0.265557</td>\n",
       "      <td>0.234304</td>\n",
       "      <td>-0.477310</td>\n",
       "      <td>0.192237</td>\n",
       "      <td>0.193429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>-0.046386</td>\n",
       "      <td>-0.061463</td>\n",
       "      <td>-0.041949</td>\n",
       "      <td>0.089724</td>\n",
       "      <td>-0.117973</td>\n",
       "      <td>-0.276404</td>\n",
       "      <td>-0.012729</td>\n",
       "      <td>0.356145</td>\n",
       "      <td>-0.470224</td>\n",
       "      <td>-0.170283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606497</td>\n",
       "      <td>-0.333302</td>\n",
       "      <td>0.091526</td>\n",
       "      <td>0.202758</td>\n",
       "      <td>0.252701</td>\n",
       "      <td>-0.215177</td>\n",
       "      <td>0.185192</td>\n",
       "      <td>-0.528985</td>\n",
       "      <td>0.254846</td>\n",
       "      <td>0.247713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9612</th>\n",
       "      <td>-0.041802</td>\n",
       "      <td>-0.048932</td>\n",
       "      <td>-0.048242</td>\n",
       "      <td>0.124537</td>\n",
       "      <td>-0.147270</td>\n",
       "      <td>-0.242986</td>\n",
       "      <td>0.016474</td>\n",
       "      <td>0.335927</td>\n",
       "      <td>-0.451703</td>\n",
       "      <td>-0.144594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556747</td>\n",
       "      <td>-0.310317</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>0.209893</td>\n",
       "      <td>0.212469</td>\n",
       "      <td>-0.215106</td>\n",
       "      <td>0.196116</td>\n",
       "      <td>-0.526052</td>\n",
       "      <td>0.217108</td>\n",
       "      <td>0.252636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>-0.046434</td>\n",
       "      <td>-0.076680</td>\n",
       "      <td>-0.023759</td>\n",
       "      <td>0.085632</td>\n",
       "      <td>-0.139343</td>\n",
       "      <td>-0.194416</td>\n",
       "      <td>-0.024847</td>\n",
       "      <td>0.274385</td>\n",
       "      <td>-0.364096</td>\n",
       "      <td>-0.104656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514042</td>\n",
       "      <td>-0.265569</td>\n",
       "      <td>0.092049</td>\n",
       "      <td>0.186155</td>\n",
       "      <td>0.145397</td>\n",
       "      <td>-0.195049</td>\n",
       "      <td>0.184652</td>\n",
       "      <td>-0.446149</td>\n",
       "      <td>0.144857</td>\n",
       "      <td>0.226070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9614</th>\n",
       "      <td>-0.008997</td>\n",
       "      <td>-0.123929</td>\n",
       "      <td>-0.065562</td>\n",
       "      <td>0.165538</td>\n",
       "      <td>-0.057090</td>\n",
       "      <td>-0.207213</td>\n",
       "      <td>-0.067598</td>\n",
       "      <td>0.287983</td>\n",
       "      <td>-0.487435</td>\n",
       "      <td>-0.213323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651121</td>\n",
       "      <td>-0.319358</td>\n",
       "      <td>0.114711</td>\n",
       "      <td>0.273162</td>\n",
       "      <td>0.297269</td>\n",
       "      <td>-0.186339</td>\n",
       "      <td>0.116715</td>\n",
       "      <td>-0.517984</td>\n",
       "      <td>0.193891</td>\n",
       "      <td>0.212167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9615 rows Ã 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -1.308204531669616699e-01  -9.373525977134704590e-01  \\\n",
       "0                      0.191728                  -0.337386   \n",
       "1                     -0.666284                   0.405146   \n",
       "2                      0.082193                  -0.953947   \n",
       "3                      0.151991                   0.003838   \n",
       "4                     -0.412334                  -0.637332   \n",
       "...                         ...                        ...   \n",
       "9610                  -0.014765                  -0.089912   \n",
       "9611                  -0.046386                  -0.061463   \n",
       "9612                  -0.041802                  -0.048932   \n",
       "9613                  -0.046434                  -0.076680   \n",
       "9614                  -0.008997                  -0.123929   \n",
       "\n",
       "      -1.903456151485443115e-01  8.866167664527893066e-01  \\\n",
       "0                     -0.133508                  0.583781   \n",
       "1                      0.261234                  0.966058   \n",
       "2                      0.041595                  0.446591   \n",
       "3                     -0.415382                  0.517119   \n",
       "4                     -0.116872                  0.365549   \n",
       "...                         ...                       ...   \n",
       "9610                  -0.059354                  0.109058   \n",
       "9611                  -0.041949                  0.089724   \n",
       "9612                  -0.048242                  0.124537   \n",
       "9613                  -0.023759                  0.085632   \n",
       "9614                  -0.065562                  0.165538   \n",
       "\n",
       "      -2.364774942398071289e-01  -4.611333608627319336e-01  \\\n",
       "0                      0.054748                  -0.359095   \n",
       "1                     -0.186964                  -0.124168   \n",
       "2                      0.255977                  -0.500937   \n",
       "3                      0.114304                   0.106529   \n",
       "4                     -0.076938                  -0.705615   \n",
       "...                         ...                        ...   \n",
       "9610                  -0.114996                  -0.218520   \n",
       "9611                  -0.117973                  -0.276404   \n",
       "9612                  -0.147270                  -0.242986   \n",
       "9613                  -0.139343                  -0.194416   \n",
       "9614                  -0.057090                  -0.207213   \n",
       "\n",
       "      -3.990370035171508789e-01  4.677708260715007782e-03  \\\n",
       "0                     -0.285114                 -0.410546   \n",
       "1                      0.119240                  0.573752   \n",
       "2                      0.635074                  1.076976   \n",
       "3                     -0.197031                  0.141737   \n",
       "4                     -0.593116                 -0.198439   \n",
       "...                         ...                       ...   \n",
       "9610                  -0.085448                  0.297680   \n",
       "9611                  -0.012729                  0.356145   \n",
       "9612                   0.016474                  0.335927   \n",
       "9613                  -0.024847                  0.274385   \n",
       "9614                  -0.067598                  0.287983   \n",
       "\n",
       "      -1.037948727607727051e+00  -4.934164285659790039e-01  ...  \\\n",
       "0                     -1.203608                  -0.559385  ...   \n",
       "1                     -0.516475                  -0.772345  ...   \n",
       "2                     -1.133167                  -0.281876  ...   \n",
       "3                     -1.134646                  -0.624014  ...   \n",
       "4                     -0.859540                  -0.925937  ...   \n",
       "...                         ...                        ...  ...   \n",
       "9610                  -0.398717                  -0.181221  ...   \n",
       "9611                  -0.470224                  -0.170283  ...   \n",
       "9612                  -0.451703                  -0.144594  ...   \n",
       "9613                  -0.364096                  -0.104656  ...   \n",
       "9614                  -0.487435                  -0.213323  ...   \n",
       "\n",
       "      4.002290666103363037e-01  -6.634631752967834473e-01  \\\n",
       "0                     1.016586                  -0.961386   \n",
       "1                     1.760169                  -0.822677   \n",
       "2                     1.177377                  -0.482142   \n",
       "3                     0.848399                  -0.904153   \n",
       "4                     1.011723                   0.839060   \n",
       "...                        ...                        ...   \n",
       "9610                  0.491519                  -0.310350   \n",
       "9611                  0.606497                  -0.333302   \n",
       "9612                  0.556747                  -0.310317   \n",
       "9613                  0.514042                  -0.265569   \n",
       "9614                  0.651121                  -0.319358   \n",
       "\n",
       "      -4.466506242752075195e-01  4.443196654319763184e-01  \\\n",
       "0                      0.080649                  0.595540   \n",
       "1                     -1.047733                  1.061342   \n",
       "2                      0.625845                  0.280632   \n",
       "3                     -0.054174                  0.541750   \n",
       "4                      0.433474                  0.125990   \n",
       "...                         ...                       ...   \n",
       "9610                   0.096876                  0.256428   \n",
       "9611                   0.091526                  0.202758   \n",
       "9612                   0.086251                  0.209893   \n",
       "9613                   0.092049                  0.186155   \n",
       "9614                   0.114711                  0.273162   \n",
       "\n",
       "      2.412061840295791626e-01  -3.203268349170684814e-01  \\\n",
       "0                     0.835402                  -0.125174   \n",
       "1                    -0.173978                  -0.848040   \n",
       "2                     0.309906                  -0.222284   \n",
       "3                     0.535916                  -0.321128   \n",
       "4                     0.484771                  -0.472632   \n",
       "...                        ...                        ...   \n",
       "9610                  0.243989                  -0.265557   \n",
       "9611                  0.252701                  -0.215177   \n",
       "9612                  0.212469                  -0.215106   \n",
       "9613                  0.145397                  -0.195049   \n",
       "9614                  0.297269                  -0.186339   \n",
       "\n",
       "      5.735866725444793701e-02  -1.806772649288177490e-01  \\\n",
       "0                     0.412031                  -0.797428   \n",
       "1                     0.719524                  -0.480560   \n",
       "2                     0.277571                  -0.852292   \n",
       "3                     0.732958                  -0.565319   \n",
       "4                     0.437122                  -1.083687   \n",
       "...                        ...                        ...   \n",
       "9610                  0.234304                  -0.477310   \n",
       "9611                  0.185192                  -0.528985   \n",
       "9612                  0.196116                  -0.526052   \n",
       "9613                  0.184652                  -0.446149   \n",
       "9614                  0.116715                  -0.517984   \n",
       "\n",
       "      -1.404088884592056274e-01  2.504607439041137695e-01  \n",
       "0                     -0.610982                  0.626047  \n",
       "1                      0.090974                  0.356793  \n",
       "2                     -0.221956                  0.398970  \n",
       "3                     -0.470649                  0.639322  \n",
       "4                      0.757188                  0.826228  \n",
       "...                         ...                       ...  \n",
       "9610                   0.192237                  0.193429  \n",
       "9611                   0.254846                  0.247713  \n",
       "9612                   0.217108                  0.252636  \n",
       "9613                   0.144857                  0.226070  \n",
       "9614                   0.193891                  0.212167  \n",
       "\n",
       "[9615 rows x 50 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"saved_word_vectors_vectors.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to:\n",
    "\n",
    "- Now, [open this link](https://projector.tensorflow.org/), and select \"load\".\n",
    "- look for saved_word_vectors_vectors.tsv and saved_word_vectors_metadata.tsv. \n",
    "\n",
    "=> These are respectively, the items latent representations and their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters matter when using Word2Vec for Item recommendation:\n",
    "\n",
    "\n",
    "> Skip-gram with negative sampling, a popular variant of Word2vec originally designed and tuned to create word embeddings for Natural Language Processing, has been used to create item embeddings with successful applications in recommendation. While these fields do not share the same type of data, neither evaluate on the same tasks, recommendation applications tend to use the same already tuned hyperparameters values, even if optimal hyperparameters values are often known to be data and task dependent. We thus investigate the marginal importance of each hyperparameter in a recommendation setting through large hyperparameter grid searches on various datasets. Results reveal that optimizing neglected hyperparameters, namely negative sampling distribution, number of epochs, subsampling parameter and window-size, significantly improves performance on a recommendation task, and can increase it by an order of magnitude. Importantly, we find that optimal hyperparameters configurations for Natural Language Processing tasks and Recommendation tasks are noticeably different. \n",
    "\n",
    "[Hyperparameters matter](https://arxiv.org/abs/1804.04212)\n",
    "\n",
    "#### It turns out that  hyperparameters are really important for this task: especially the sampling parameter.  Try and learn multiple models to see how the ns_exponent parameter modifies the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 17:26:17,522 : INFO : collecting all words and their counts\n",
      "2022-04-29 17:26:17,523 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-04-29 17:26:17,532 : INFO : collected 9616 word types from a corpus of 97786 raw words and 610 sentences\n",
      "2022-04-29 17:26:17,533 : INFO : Creating a fresh vocabulary\n",
      "2022-04-29 17:26:17,555 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 9616 unique words (100.0%% of original 9616, drops 0)', 'datetime': '2022-04-29T17:26:17.555719', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-29 17:26:17,556 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 97786 word corpus (100.0%% of original 97786, drops 0)', 'datetime': '2022-04-29T17:26:17.556219', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-29 17:26:17,598 : INFO : deleting the raw counts dictionary of 9616 items\n",
      "2022-04-29 17:26:17,598 : INFO : sample=0.001 downsamples 5 most-common words\n",
      "2022-04-29 17:26:17,599 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 97657.99863393226 word corpus (99.9%% of prior 97786)', 'datetime': '2022-04-29T17:26:17.599227', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "2022-04-29 17:26:17,673 : INFO : estimated required memory for 9616 words and 50 dimensions: 8654400 bytes\n",
      "2022-04-29 17:26:17,674 : INFO : resetting layer weights\n",
      "2022-04-29 17:26:17,676 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-04-29T17:26:17.676741', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'build_vocab'}\n",
      "2022-04-29 17:26:17,677 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 9616 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=3 shrink_windows=True', 'datetime': '2022-04-29T17:26:17.676741', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'train'}\n",
      "2022-04-29 17:26:17,808 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:17,813 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:17,813 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:17,817 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:17,819 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:17,821 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:17,822 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:17,824 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:17,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:17,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:17,826 : INFO : EPOCH - 1 : training on 97786 raw words (97672 effective words) took 0.1s, 666514 effective words/s\n",
      "2022-04-29 17:26:17,943 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:17,947 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:17,953 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:17,958 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:17,960 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:17,960 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:17,962 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:17,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:17,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:17,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:17,966 : INFO : EPOCH - 2 : training on 97786 raw words (97679 effective words) took 0.1s, 714774 effective words/s\n",
      "2022-04-29 17:26:18,077 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,091 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,095 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,097 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,097 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,098 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,101 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,101 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,104 : INFO : EPOCH - 3 : training on 97786 raw words (97671 effective words) took 0.1s, 725291 effective words/s\n",
      "2022-04-29 17:26:18,220 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,235 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,239 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,241 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,242 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,244 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,245 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,246 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,247 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,250 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,251 : INFO : EPOCH - 4 : training on 97786 raw words (97650 effective words) took 0.1s, 681927 effective words/s\n",
      "2022-04-29 17:26:18,355 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,372 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,379 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,382 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,383 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,383 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,384 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,389 : INFO : EPOCH - 5 : training on 97786 raw words (97659 effective words) took 0.1s, 723617 effective words/s\n",
      "2022-04-29 17:26:18,499 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,509 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,513 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,514 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,518 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,519 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,519 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,520 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,527 : INFO : EPOCH - 6 : training on 97786 raw words (97658 effective words) took 0.1s, 723409 effective words/s\n",
      "2022-04-29 17:26:18,631 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,642 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,650 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,651 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,654 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,658 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,661 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,662 : INFO : EPOCH - 7 : training on 97786 raw words (97673 effective words) took 0.1s, 738128 effective words/s\n",
      "2022-04-29 17:26:18,772 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,792 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,793 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,798 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,798 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,799 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,799 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,807 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,808 : INFO : EPOCH - 8 : training on 97786 raw words (97661 effective words) took 0.1s, 688078 effective words/s\n",
      "2022-04-29 17:26:18,918 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:18,928 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:18,930 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:18,931 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:18,932 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:18,935 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:18,936 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:18,938 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:18,940 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:18,940 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:18,941 : INFO : EPOCH - 9 : training on 97786 raw words (97653 effective words) took 0.1s, 753326 effective words/s\n",
      "2022-04-29 17:26:19,048 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,063 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,066 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,069 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,074 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,076 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,078 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,080 : INFO : EPOCH - 10 : training on 97786 raw words (97662 effective words) took 0.1s, 717783 effective words/s\n",
      "2022-04-29 17:26:19,186 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,200 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,203 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,204 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,207 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,208 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,208 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,212 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,213 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,214 : INFO : EPOCH - 11 : training on 97786 raw words (97644 effective words) took 0.1s, 748532 effective words/s\n",
      "2022-04-29 17:26:19,315 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,330 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,338 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,339 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,342 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,343 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,343 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,349 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,349 : INFO : EPOCH - 12 : training on 97786 raw words (97665 effective words) took 0.1s, 741233 effective words/s\n",
      "2022-04-29 17:26:19,460 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,468 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,469 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,476 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,477 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,478 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,480 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,484 : INFO : EPOCH - 13 : training on 97786 raw words (97661 effective words) took 0.1s, 743506 effective words/s\n",
      "2022-04-29 17:26:19,584 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,603 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,605 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,609 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,611 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,612 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,614 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,615 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,617 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,618 : INFO : EPOCH - 14 : training on 97786 raw words (97665 effective words) took 0.1s, 748520 effective words/s\n",
      "2022-04-29 17:26:19,730 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,737 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,740 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,741 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,747 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,748 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,748 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,753 : INFO : EPOCH - 15 : training on 97786 raw words (97663 effective words) took 0.1s, 738760 effective words/s\n",
      "2022-04-29 17:26:19,864 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:19,872 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:19,872 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:19,873 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:19,879 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:19,879 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:19,881 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:19,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:19,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:19,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:19,886 : INFO : EPOCH - 16 : training on 97786 raw words (97665 effective words) took 0.1s, 756099 effective words/s\n",
      "2022-04-29 17:26:19,992 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,005 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,009 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,013 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,014 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,014 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,015 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,018 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,018 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,023 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,024 : INFO : EPOCH - 17 : training on 97786 raw words (97647 effective words) took 0.1s, 730783 effective words/s\n",
      "2022-04-29 17:26:20,123 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,142 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,144 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,145 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,147 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,149 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,154 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,155 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,155 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,158 : INFO : EPOCH - 18 : training on 97786 raw words (97659 effective words) took 0.1s, 747704 effective words/s\n",
      "2022-04-29 17:26:20,263 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,275 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,280 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,283 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,283 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,286 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,287 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,290 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,292 : INFO : EPOCH - 19 : training on 97786 raw words (97659 effective words) took 0.1s, 744591 effective words/s\n",
      "2022-04-29 17:26:20,396 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,410 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,412 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,413 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,416 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,419 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,419 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,422 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,423 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,424 : INFO : EPOCH - 20 : training on 97786 raw words (97678 effective words) took 0.1s, 755515 effective words/s\n",
      "2022-04-29 17:26:20,531 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,545 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,548 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,551 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,554 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,555 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,556 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,562 : INFO : EPOCH - 21 : training on 97786 raw words (97667 effective words) took 0.1s, 729097 effective words/s\n",
      "2022-04-29 17:26:20,664 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,678 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,684 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,685 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,689 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,690 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,694 : INFO : EPOCH - 22 : training on 97786 raw words (97666 effective words) took 0.1s, 761798 effective words/s\n",
      "2022-04-29 17:26:20,798 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,816 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,817 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,819 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,822 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,823 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,823 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,825 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,828 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,830 : INFO : EPOCH - 23 : training on 97786 raw words (97663 effective words) took 0.1s, 736129 effective words/s\n",
      "2022-04-29 17:26:20,935 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:20,950 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:20,953 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:20,955 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:20,958 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:20,958 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:20,959 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:20,959 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:20,965 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:20,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:20,967 : INFO : EPOCH - 24 : training on 97786 raw words (97653 effective words) took 0.1s, 732199 effective words/s\n",
      "2022-04-29 17:26:21,072 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-04-29 17:26:21,086 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-04-29 17:26:21,091 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-04-29 17:26:21,091 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-04-29 17:26:21,094 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-04-29 17:26:21,095 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-04-29 17:26:21,095 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-04-29 17:26:21,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-04-29 17:26:21,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-04-29 17:26:21,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-29 17:26:21,100 : INFO : EPOCH - 25 : training on 97786 raw words (97661 effective words) took 0.1s, 746198 effective words/s\n",
      "2022-04-29 17:26:21,101 : INFO : Word2Vec lifecycle event {'msg': 'training on 2444650 raw words (2441554 effective words) took 3.4s, 713043 effective words/s', 'datetime': '2022-04-29T17:26:21.101343', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'train'}\n",
      "2022-04-29 17:26:21,101 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=9616, vector_size=50, alpha=0.025)', 'datetime': '2022-04-29T17:26:21.101843', 'gensim': '4.1.2', 'python': '3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# the following configuration is the default configuration\n",
    "# Same modifications as before (size and iter replaced by vector_size and epochs)\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=train_seq_str,\n",
    "                                vector_size=50, window=3,               ### here we train a cbow model \n",
    "                                min_count=0,                      \n",
    "                                sample=0.001, ns_exponent=-0.4, workers=10,\n",
    "                                sg=1, hs=0, negative=15,          ### set sg to 1 to train a sg model => Prod2Vec\n",
    "                                cbow_mean=0,\n",
    "                                epochs=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_preds = get_predictions(predict_pop,last_consumed_item,test_seq,-1)\n",
    "w2v_preds = get_predictions(predict_w2v,last_consumed_item,test_seq,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.87234931650308\n",
      "12.268373706288253\n",
      "0.051054704276776476\n",
      "0.09120217861070297\n",
      "0.017315723982695277\n",
      "0.03121773183451276\n"
     ]
    }
   ],
   "source": [
    "print(1/mrr(pop_preds))\n",
    "print(1/mrr(w2v_preds))\n",
    "\n",
    "print(mean_dcg(pop_preds,5))\n",
    "print(mean_dcg(w2v_preds,5))\n",
    "\n",
    "print(mean_ndcg(pop_preds,5))\n",
    "print(mean_ndcg(w2v_preds,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still got time ? Try making a more clever item selection mechanism:\n",
    "\n",
    "- You could, for example, cluster items in groups (using k-means) and propose the most popular items of the last seen group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
